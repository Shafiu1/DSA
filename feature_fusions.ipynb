{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8emL32W7DJKgVJngwN86H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shafiu1/DSA/blob/main/feature_fusions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo1yS2BEgN4U"
      },
      "outputs": [],
      "source": [
        "# bangla_news_classifier.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle as pkl\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "folder_path = \"/content/drive/MyDrive/BanglaNewsClassifier/\"\n",
        "dataset_path = \"/content/drive/MyDrive/BanglaNewsClassifier/Images/\"\n",
        "\n",
        "# Load and prepare dataset\n",
        "df = pd.read_csv(folder_path + 'headlines.csv')\n",
        "df['full_image_path'] = df['Image_Path'].apply(lambda x: f\"{dataset_path}{x}\")\n",
        "\n",
        "# Split data\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.33, random_state=42)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(train_df['Category(Bangla)'])\n",
        "val_labels = le.transform(val_df['Category(Bangla)'])\n",
        "test_labels = le.transform(test_df['Category(Bangla)'])\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "# Image preprocessing\n",
        "def process_image(image_path):\n",
        "    img = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array)[0].astype(np.float32)\n",
        "\n",
        "def load_or_process_images(df, save_path):\n",
        "    if os.path.exists(save_path):\n",
        "        with open(save_path, 'rb') as f:\n",
        "            images = pkl.load(f)\n",
        "    else:\n",
        "        images = np.array([process_image(path) for path in df['full_image_path']])\n",
        "        with open(save_path, 'wb') as f:\n",
        "            pkl.dump(images, f)\n",
        "    return images\n",
        "\n",
        "train_images = load_or_process_images(train_df, folder_path + 'train_images.pkl')\n",
        "val_images = load_or_process_images(val_df, folder_path + 'val_images.pkl')\n",
        "test_images = load_or_process_images(test_df, folder_path + 'test_images.pkl')\n",
        "\n",
        "# Text preprocessing\n",
        "tokenizer = Tokenizer(num_words=50000, oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(df['Heading(Bangla)'])\n",
        "max_len = 128\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['Heading(Bangla)'])\n",
        "val_sequences = tokenizer.texts_to_sequences(val_df['Heading(Bangla)'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['Heading(Bangla)'])\n",
        "\n",
        "train_pad_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post', value=0.0)\n",
        "val_pad_sequences = pad_sequences(val_sequences, maxlen=max_len, padding='post', value=0.0)\n",
        "test_pad_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post', value=0.0)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "visual_input = Input(shape=(224, 224, 3))\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_tensor=visual_input)\n",
        "for layer in resnet.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "text_input = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(len(tokenizer.word_index) + 1, 100)(text_input)\n",
        "lstm_layer = Bidirectional(LSTM(128, dropout=0.2))(embedding_layer)\n",
        "\n",
        "concat_layer = Concatenate()([x, lstm_layer])\n",
        "x = Dropout(0.2)(concat_layer)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[visual_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # CHANGED: Changed loss from 'sparse_categorical_crossentropy' to 'categorical_crossentropy'\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Convert labels to one-hot for training\n",
        "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
        "val_labels_one_hot = tf.keras.utils.to_categorical(val_labels, num_classes)\n",
        "\n",
        "# Add early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit([train_images, train_pad_sequences], train_labels_one_hot,\n",
        "                    validation_data=([val_images, val_pad_sequences], val_labels_one_hot),\n",
        "                    epochs=10, batch_size=8, class_weight=class_weights,\n",
        "                    callbacks=[tf.keras.callbacks.ModelCheckpoint(folder_path + 'best_model.h5',\n",
        "                                                                 monitor='val_accuracy', save_best_only=True),\n",
        "                               early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
        "test_loss, test_accuracy = model.evaluate([test_images, test_pad_sequences], test_labels_one_hot)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "y_pred = model.predict([test_images, test_pad_sequences])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, y_pred_classes, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeRts_IIn75v",
        "outputId": "909e1ec7-4afc-48a4-cb75-1a33d70ee505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5061 - loss: 1.4098"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.5065 - loss: 1.4088 - val_accuracy: 0.6861 - val_loss: 1.1280\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8493 - loss: 0.4345"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 95ms/step - accuracy: 0.8494 - loss: 0.4345 - val_accuracy: 0.7630 - val_loss: 0.9149\n",
            "Epoch 3/10\n",
            "\u001b[1m350/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9530 - loss: 0.1459"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 104ms/step - accuracy: 0.9530 - loss: 0.1458 - val_accuracy: 0.8548 - val_loss: 0.4934\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 60ms/step - accuracy: 0.9788 - loss: 0.0801 - val_accuracy: 0.8536 - val_loss: 0.5519\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 56ms/step - accuracy: 0.9938 - loss: 0.0237 - val_accuracy: 0.8387 - val_loss: 0.7474\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.9935 - loss: 0.0162 - val_accuracy: 0.8400 - val_loss: 0.8523\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8384 - loss: 0.5854\n",
            "Test accuracy: 0.8413\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 363ms/step\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "  অর্থনীতি ও বাণিজ্য       0.87      0.85      0.86        53\n",
            "            খেলাধুলা       0.85      0.93      0.89        74\n",
            "           প্রযুক্তি       0.86      0.91      0.88        66\n",
            "              বিনোদন       0.85      0.68      0.76        66\n",
            "             রাজনীতি       0.93      0.87      0.90        62\n",
            "স্বাস্থ্য ও জীবনযাপন       0.73      0.80      0.77        76\n",
            "\n",
            "            accuracy                           0.84       397\n",
            "           macro avg       0.85      0.84      0.84       397\n",
            "        weighted avg       0.84      0.84      0.84       397\n",
            "\n"
          ]
        }
      ]
    }
  ]
}